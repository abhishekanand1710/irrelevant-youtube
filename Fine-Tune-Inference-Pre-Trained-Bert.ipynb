{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Data from - [Github](https://github.com/Rhitabrat/Youtube-Comments-Categorization), [Paper](https://arxiv.org/pdf/2111.01908.pdf)","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers\n!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T16:04:08.777718Z","iopub.execute_input":"2023-05-21T16:04:08.778067Z","iopub.status.idle":"2023-05-21T16:04:33.932561Z","shell.execute_reply.started":"2023-05-21T16:04:08.778037Z","shell.execute_reply":"2023-05-21T16:04:33.931395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom string import digits\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nimport re\nfrom tqdm import tqdm, notebook\n\nimport time\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-05-23T17:14:10.493661Z","iopub.execute_input":"2023-05-23T17:14:10.493939Z","iopub.status.idle":"2023-05-23T17:14:12.298855Z","shell.execute_reply.started":"2023-05-23T17:14:10.493914Z","shell.execute_reply":"2023-05-23T17:14:12.297814Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n/kaggle/input/youtube-comments-categorization/youtube-comments-categorization.csv\n/kaggle/input/youtube-videos-title-description-comments/GBvideos.csv\n/kaggle/input/youtube-videos-title-description-comments/GBtext-details.csv\n/kaggle/input/youtube-videos-title-description-comments/UScomments.csv\n/kaggle/input/youtube-videos-title-description-comments/GB_category_id.json\n/kaggle/input/youtube-videos-title-description-comments/US_category_id.json\n/kaggle/input/youtube-videos-title-description-comments/UStext-details.csv\n/kaggle/input/youtube-videos-title-description-comments/GBcomments.csv\n/kaggle/input/youtube-videos-title-description-comments/USvideos.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport gc\nfrom pprint import pprint\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.06703Z","iopub.execute_input":"2023-05-21T16:04:46.069432Z","iopub.status.idle":"2023-05-21T16:04:46.14536Z","shell.execute_reply.started":"2023-05-21T16:04:46.069397Z","shell.execute_reply":"2023-05-21T16:04:46.14452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.147811Z","iopub.execute_input":"2023-05-21T16:04:46.148134Z","iopub.status.idle":"2023-05-21T16:04:46.153133Z","shell.execute_reply.started":"2023-05-21T16:04:46.148103Z","shell.execute_reply":"2023-05-21T16:04:46.152267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\nDATA_PATH = '/kaggle/input/youtube-comments-categorization/youtube-comments-categorization.csv'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device.type)\n\nSEED = 97\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.154373Z","iopub.execute_input":"2023-05-21T16:04:46.154856Z","iopub.status.idle":"2023-05-21T16:04:46.190292Z","shell.execute_reply.started":"2023-05-21T16:04:46.154826Z","shell.execute_reply":"2023-05-21T16:04:46.189258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying 3 bert based models without pre-training","metadata":{}},{"cell_type":"code","source":"BERT = 'bert-base-uncased'\nDISTIL_BERT = 'distilbert-base-uncased'\nROBERTA = 'roberta-base'","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.191644Z","iopub.execute_input":"2023-05-21T16:04:46.192544Z","iopub.status.idle":"2023-05-21T16:04:46.199259Z","shell.execute_reply.started":"2023-05-21T16:04:46.192513Z","shell.execute_reply":"2023-05-21T16:04:46.198327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg ={}\n\nMODEL_PATH = ROBERTA","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.202082Z","iopub.execute_input":"2023-05-21T16:04:46.202864Z","iopub.status.idle":"2023-05-21T16:04:46.20808Z","shell.execute_reply.started":"2023-05-21T16:04:46.202839Z","shell.execute_reply":"2023-05-21T16:04:46.207084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(DATA_PATH, header = None)\ndf.columns = ['comment', 'label']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.209413Z","iopub.execute_input":"2023-05-21T16:04:46.209926Z","iopub.status.idle":"2023-05-21T16:04:46.273371Z","shell.execute_reply.started":"2023-05-21T16:04:46.209895Z","shell.execute_reply":"2023-05-21T16:04:46.272256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.274824Z","iopub.execute_input":"2023-05-21T16:04:46.275171Z","iopub.status.idle":"2023-05-21T16:04:46.281677Z","shell.execute_reply.started":"2023-05-21T16:04:46.275138Z","shell.execute_reply":"2023-05-21T16:04:46.280574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots()\nlabels = df.label.unique()\nax.set_xticklabels(labels=labels, rotation=45)\nsns.countplot(x='label', data=df, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.287626Z","iopub.execute_input":"2023-05-21T16:04:46.287905Z","iopub.status.idle":"2023-05-21T16:04:46.613828Z","shell.execute_reply.started":"2023-05-21T16:04:46.28788Z","shell.execute_reply":"2023-05-21T16:04:46.612906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.label.unique()\nlabels = {'positive':0, 'imperative':1, 'interrogative':2, 'miscellaneous':3,\n       'corrective':4, 'negative':5}\ndf['enc_label'] = df.label.apply(lambda x: labels[x])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.615041Z","iopub.execute_input":"2023-05-21T16:04:46.615818Z","iopub.status.idle":"2023-05-21T16:04:46.637887Z","shell.execute_reply.started":"2023-05-21T16:04:46.615784Z","shell.execute_reply":"2023-05-21T16:04:46.637025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_temp, y_train, y_temp = train_test_split(df.comment, df.enc_label, test_size=0.3, random_state=SEED, stratify=df.enc_label)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.639364Z","iopub.execute_input":"2023-05-21T16:04:46.639704Z","iopub.status.idle":"2023-05-21T16:04:46.65679Z","shell.execute_reply.started":"2023-05-21T16:04:46.639674Z","shell.execute_reply":"2023-05-21T16:04:46.655983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots()\n# labels = df.label.unique()\n# ax.set_xticklabels(labels=labels, rotation=45)\nsns.countplot(x=y_train, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.65824Z","iopub.execute_input":"2023-05-21T16:04:46.658577Z","iopub.status.idle":"2023-05-21T16:04:46.93486Z","shell.execute_reply.started":"2023-05-21T16:04:46.658548Z","shell.execute_reply":"2023-05-21T16:04:46.933935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots()\n# labels = df.label.unique()\n# ax.set_xticklabels(labels=labels, rotation=45)\nsns.countplot(x=y_val, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:46.936372Z","iopub.execute_input":"2023-05-21T16:04:46.936973Z","iopub.status.idle":"2023-05-21T16:04:47.207983Z","shell.execute_reply.started":"2023-05-21T16:04:46.936938Z","shell.execute_reply":"2023-05-21T16:04:47.207078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots()\n# labels = df.label.unique()\n# ax.set_xticklabels(labels=labels, rotation=45)\nsns.countplot(x=y_test, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:47.209483Z","iopub.execute_input":"2023-05-21T16:04:47.210086Z","iopub.status.idle":"2023-05-21T16:04:47.479214Z","shell.execute_reply.started":"2023-05-21T16:04:47.21005Z","shell.execute_reply":"2023-05-21T16:04:47.478344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\nval_df = pd.concat([X_val, y_val], axis=1).reset_index(drop=True)\ntest_df = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:47.480743Z","iopub.execute_input":"2023-05-21T16:04:47.481079Z","iopub.status.idle":"2023-05-21T16:04:47.490939Z","shell.execute_reply.started":"2023-05-21T16:04:47.481048Z","shell.execute_reply":"2023-05-21T16:04:47.490089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:47.492117Z","iopub.execute_input":"2023-05-21T16:04:47.492892Z","iopub.status.idle":"2023-05-21T16:04:47.508575Z","shell.execute_reply.started":"2023-05-21T16:04:47.492848Z","shell.execute_reply":"2023-05-21T16:04:47.507604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['tokenizer'] ={'name': MODEL_PATH, 'max_length': 256}\ntokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:47.509951Z","iopub.execute_input":"2023-05-21T16:04:47.510719Z","iopub.status.idle":"2023-05-21T16:04:50.15918Z","shell.execute_reply.started":"2023-05-21T16:04:47.510684Z","shell.execute_reply":"2023-05-21T16:04:50.158238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['train_batch_size'] = 32\ncfg['valid_batch_size'] = 16\ncfg['max_length'] = 256\ncfg['epochs'] = 3\ncfg['learning_rate'] = 1e-05","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.160749Z","iopub.execute_input":"2023-05-21T16:04:50.161115Z","iopub.status.idle":"2023-05-21T16:04:50.166576Z","shell.execute_reply.started":"2023-05-21T16:04:50.161082Z","shell.execute_reply":"2023-05-21T16:04:50.165354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommentsDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.len = len(df)\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __getitem__(self, index):\n        comment = self.df.loc[index, 'comment']\n        inputs = self.tokenizer.encode_plus(\n            comment,                                 \n            add_special_tokens=True,\n            padding='max_length',\n            max_length=self.max_len,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        \n        if cfg['tokenizer']['name']=='bert-base-uncased':\n            token_type_ids = inputs['token_type_ids'] \n        else:\n            token_type_ids = 1.\n        \n        target = self.df.loc[index, 'enc_label']\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'masks': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(target, dtype=torch.long)\n        }\n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.16815Z","iopub.execute_input":"2023-05-21T16:04:50.168893Z","iopub.status.idle":"2023-05-21T16:04:50.179105Z","shell.execute_reply.started":"2023-05-21T16:04:50.168861Z","shell.execute_reply":"2023-05-21T16:04:50.177985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = CommentsDataset(train_df, tokenizer, cfg['max_length'])\nval_data = CommentsDataset(val_df, tokenizer, cfg['max_length'])\ntest_data = CommentsDataset(test_df, tokenizer, cfg['max_length'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.180576Z","iopub.execute_input":"2023-05-21T16:04:50.180977Z","iopub.status.idle":"2023-05-21T16:04:50.192617Z","shell.execute_reply.started":"2023-05-21T16:04:50.180902Z","shell.execute_reply":"2023-05-21T16:04:50.191664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(data):\n    text = []\n    target = []\n    for tupl in data:\n        text.append(tupl[0])\n        target.append(tupl[1])\n    zipped = zip(text, target)\n    return list(zipped)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.193972Z","iopub.execute_input":"2023-05-21T16:04:50.194374Z","iopub.status.idle":"2023-05-21T16:04:50.202554Z","shell.execute_reply.started":"2023-05-21T16:04:50.194342Z","shell.execute_reply":"2023-05-21T16:04:50.20164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = {'batch_size': cfg['train_batch_size'],\n                'shuffle': True,\n                'num_workers': 0\n                }\n\nvalid_params = {'batch_size': cfg['valid_batch_size'],\n                'shuffle': False,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': cfg['valid_batch_size'],\n                'shuffle': False,\n                'num_workers': 0\n                }\n\n# train_loader = DataLoader(train_data, **train_params, collate_fn=collate_fn)\n# val_loader = DataLoader(val_data, **valid_params, collate_fn=collate_fn)\n# test_loader = DataLoader(test_data, **test_params, collate_fn=collate_fn)\n\ntrain_loader = DataLoader(train_data, **train_params)\nval_loader = DataLoader(val_data, **valid_params)\ntest_loader = DataLoader(test_data, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.204046Z","iopub.execute_input":"2023-05-21T16:04:50.204448Z","iopub.status.idle":"2023-05-21T16:04:50.212877Z","shell.execute_reply.started":"2023-05-21T16:04:50.204364Z","shell.execute_reply":"2023-05-21T16:04:50.211959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommentRelevanceBERT(torch.nn.Module):\n    def __init__(self, model_name, dropout=True):\n        super(CommentRelevanceBERT, self).__init__()\n        self.bert = AutoModel.from_pretrained(model_name)\n        self.model_name = model_name\n        \n        if model_name == BERT:\n            self.in_features = self.bert.pooler.dense.out_features\n        elif model_name == DISTIL_BERT:\n            self.in_features = self.bert.transformer.layer[5].output_layer_norm.normalized_shape[0]\n        elif model_name == ROBERTA:\n            self.in_features = self.bert.pooler.dense.out_features\n        else:\n            self.in_features = 768\n            \n        self.dense = nn.Linear(self.in_features, self.in_features)\n        self.activation = nn.ReLU()\n        self.layer_norm = nn.LayerNorm(self.in_features)\n        # self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, len(labels))\n\n    def forward(self, input_ids, attention_mask, token_type_ids):    \n        if self.model_name == BERT:\n            last_hidden_state, output = self.bert(input_ids,\n                                                  attention_mask=attention_mask,\n                                                  token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        elif self.model_name == DISTIL_BERT:\n            last_hidden_state = self.bert(input_ids,\n                                          attention_mask=attention_mask,\n                                          return_dict=False)\n            first_token_tensor = last_hidden_state[0][:, 0]\n            output = self.dense(first_token_tensor)\n            output = self.activation(output)\n            \n        elif self.model_name == ROBERTA:\n            last_hidden_state, output = self.bert(input_ids,\n                                                  attention_mask=attention_mask,\n                                                  return_dict=False)\n        \n        output = self.layer_norm(output)\n        # output = self.dropout(output)\n        output = self.classifier(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.215543Z","iopub.execute_input":"2023-05-21T16:04:50.216422Z","iopub.status.idle":"2023-05-21T16:04:50.229081Z","shell.execute_reply.started":"2023-05-21T16:04:50.21639Z","shell.execute_reply":"2023-05-21T16:04:50.227932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CommentRelevanceBERT(MODEL_PATH)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:50.230476Z","iopub.execute_input":"2023-05-21T16:04:50.230853Z","iopub.status.idle":"2023-05-21T16:04:57.337082Z","shell.execute_reply.started":"2023-05-21T16:04:50.230822Z","shell.execute_reply":"2023-05-21T16:04:57.336145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.338386Z","iopub.execute_input":"2023-05-21T16:04:57.338817Z","iopub.status.idle":"2023-05-21T16:04:57.349515Z","shell.execute_reply.started":"2023-05-21T16:04:57.338783Z","shell.execute_reply":"2023-05-21T16:04:57.348634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_training_steps = cfg['epochs']*len(train_loader)\nnum_warmup_steps = 0\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=cfg['learning_rate'])\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n)\n# optimizer.step()\n# scheduler.step()\n# learning_rate_history.append(optimizer.param_groups[0]['lr'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.351149Z","iopub.execute_input":"2023-05-21T16:04:57.351672Z","iopub.status.idle":"2023-05-21T16:04:57.359147Z","shell.execute_reply.started":"2023-05-21T16:04:57.351531Z","shell.execute_reply":"2023-05-21T16:04:57.358165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_accuracy(preds, targets):\n    accuracy = (preds==targets).cpu().numpy().mean() * 100\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.365776Z","iopub.execute_input":"2023-05-21T16:04:57.366037Z","iopub.status.idle":"2023-05-21T16:04:57.372696Z","shell.execute_reply.started":"2023-05-21T16:04:57.366015Z","shell.execute_reply":"2023-05-21T16:04:57.371757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, loss_fn, train_dataloader, val_dataloader=None, epochs=3, evaluation=False):\n    \n    print(\"Start training...\\n\")\n    for epoch in range(epochs):\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n        train_loss = []\n        model.train()\n\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n            model.zero_grad()\n            input_ids = batch['ids'].to(device, dtype = torch.long)\n            attention_mask = batch['masks'].to(device, dtype = torch.long)\n            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n            targets = batch['targets'].to(device, dtype = torch.long)\n\n            outputs = model(input_ids, attention_mask, token_type_ids)\n\n            loss = loss_fn(outputs, targets)\n            train_loss.append(loss.item())\n            \n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n            scheduler.step()\n\n            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                time_elapsed = time.time() - t0_batch\n\n                print(f\"{epoch + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"-\"*70)\n        \n        if evaluation == True:\n            val_loss, val_accuracy = evaluate(model, loss_fn, val_dataloader)\n            time_elapsed = time.time() - t0_epoch\n            \n            print(f\"{epoch + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            \n            print(\"-\"*70)\n        print(\"\\n\")\n    \n    print(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.376078Z","iopub.execute_input":"2023-05-21T16:04:57.376347Z","iopub.status.idle":"2023-05-21T16:04:57.389331Z","shell.execute_reply.started":"2023-05-21T16:04:57.376322Z","shell.execute_reply":"2023-05-21T16:04:57.387248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, loss_fn, val_dataloader):\n    model.eval()\n\n    val_accuracy = []\n    val_loss = []\n\n    for batch in val_dataloader:\n        input_ids = batch['ids'].to(device, dtype = torch.long)\n        attention_mask = batch['masks'].to(device, dtype = torch.long)\n        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n        targets = batch['targets'].to(device, dtype = torch.long)\n\n        with torch.no_grad():\n            outputs = model(input_ids, attention_mask, token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        val_loss.append(loss.item())\n\n        _, max_ids = torch.max(outputs.data, dim=1)\n        val_accuracy.append(calc_accuracy(max_ids, targets))\n\n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n\n    return val_loss, val_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.390898Z","iopub.execute_input":"2023-05-21T16:04:57.391733Z","iopub.status.idle":"2023-05-21T16:04:57.401458Z","shell.execute_reply.started":"2023-05-21T16:04:57.391701Z","shell.execute_reply":"2023-05-21T16:04:57.400317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning rate = 1e-03, model loss was not reducing at all. Reduced learning rate to 1e-05, loss started reducing. ","metadata":{}},{"cell_type":"code","source":"train(model, loss_function, train_loader, val_loader, epochs=5, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:04:57.403606Z","iopub.execute_input":"2023-05-21T16:04:57.404083Z","iopub.status.idle":"2023-05-21T16:12:06.260905Z","shell.execute_reply.started":"2023-05-21T16:04:57.404025Z","shell.execute_reply":"2023-05-21T16:12:06.259126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"82.25 = dropout 0.3, no layer norm, 3 epochs <br/>\n82.31 = no droputout, layer norm, 3 epochs\n82.03 = '', '', batch size = 64, distill bert, 5 epochs","metadata":{}},{"cell_type":"code","source":"output_model_file = 'roberta_youtube_comments.pth'\ntorch.save(model, output_model_file)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:06.262646Z","iopub.execute_input":"2023-05-21T16:12:06.263001Z","iopub.status.idle":"2023-05-21T16:12:06.684413Z","shell.execute_reply.started":"2023-05-21T16:12:06.262968Z","shell.execute_reply":"2023-05-21T16:12:06.683247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = evaluate(model, loss_function, test_loader)\ntest_loss, test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:06.685779Z","iopub.execute_input":"2023-05-21T16:12:06.686489Z","iopub.status.idle":"2023-05-21T16:12:12.805401Z","shell.execute_reply.started":"2023-05-21T16:12:06.686451Z","shell.execute_reply":"2023-05-21T16:12:12.804342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, loss_fn, val_dataloader):\n    model.eval()\n\n    preds = []\n\n    for batch in val_dataloader:\n        input_ids = batch['ids'].to(device, dtype = torch.long)\n        attention_mask = batch['masks'].to(device, dtype = torch.long)\n        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n        targets = batch['targets'].to(device, dtype = torch.long)\n\n        with torch.no_grad():\n            outputs = model(input_ids, attention_mask, token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        _, max_ids = torch.max(outputs.data, dim=1)\n        preds.extend(max_ids.cpu().numpy())\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:12.80686Z","iopub.execute_input":"2023-05-21T16:12:12.807231Z","iopub.status.idle":"2023-05-21T16:12:12.815316Z","shell.execute_reply.started":"2023-05-21T16:12:12.807181Z","shell.execute_reply":"2023-05-21T16:12:12.81442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predict(model, loss_function, test_loader)\nlen(preds), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:12.816578Z","iopub.execute_input":"2023-05-21T16:12:12.817093Z","iopub.status.idle":"2023-05-21T16:12:19.000876Z","shell.execute_reply.started":"2023-05-21T16:12:12.81706Z","shell.execute_reply":"2023-05-21T16:12:19.000007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:19.002276Z","iopub.execute_input":"2023-05-21T16:12:19.002607Z","iopub.status.idle":"2023-05-21T16:12:19.008528Z","shell.execute_reply.started":"2023-05-21T16:12:19.002576Z","shell.execute_reply":"2023-05-21T16:12:19.006829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:10], y_test[:10]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:19.010041Z","iopub.execute_input":"2023-05-21T16:12:19.010725Z","iopub.status.idle":"2023-05-21T16:12:19.020628Z","shell.execute_reply.started":"2023-05-21T16:12:19.010694Z","shell.execute_reply":"2023-05-21T16:12:19.019553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = classification_report(y_test, preds, labels=[0, 1, 2, 3, 4, 5])\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:19.022293Z","iopub.execute_input":"2023-05-21T16:12:19.022706Z","iopub.status.idle":"2023-05-21T16:12:19.040578Z","shell.execute_reply.started":"2023-05-21T16:12:19.022637Z","shell.execute_reply":"2023-05-21T16:12:19.039613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:12:19.04202Z","iopub.execute_input":"2023-05-21T16:12:19.042404Z","iopub.status.idle":"2023-05-21T16:12:19.308996Z","shell.execute_reply.started":"2023-05-21T16:12:19.042364Z","shell.execute_reply":"2023-05-21T16:12:19.308097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}