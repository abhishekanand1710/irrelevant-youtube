,comment,replies
0,Super helpful! Thanks for making this video,[]
1,"Thanks for the video, I am a bit confused about why use this function, for example, in that get_weather() function, all the GPT does it to extract the information to a parameter that we can feed into a function, so why not we just write a prompt to get the location as a json directly? is it because you do not know what the user would ask? so you can provide a list of functions that you wrote, and from the output, we can determine, whether the user invokes one of our functions or not, if yes, then we use the GPT output to do a further processing?  but this is actually complex, after getting the result from the your own function, how do you know how to construct the proper answer to the user? what about the user triggers 3 functions, and what should happen next? how could you provide an outcome to the user in this case (more than 1 function has been invoked)?",[]
2,"What does a working relationship with you look like? <br><br>I run a business consulting the roofing industry in their sales and service operations. We deploy that as a service by customizing enterprise grade software like hubspot and end point solutions for Configure price quote and field service management. <br><br>After 7 years Our average contract value is North of $85,000 up to $330,000 and our MRR client spend is $7500 so we have the gas in the tank to invest in establishing a beach head for Ai concepts. <br><br>The roofing industry might not seem very sexy for a person as intelligent as yourself who might not be exposed to it. However a tech minded person knows that the success of a tech product is based on the total addressable market; of which roofing benefits every human in the country. You, me, everyone lives under a roof, most work under a roof, we are entertained under a roof, we shop under a roof and our kids our educated under a roof. <br><br>Just the top 25 counties in the US represent $10b in residential roof replacements annually alone. <br><br>We think there are some great opportunities in:<br><br>1. Workforce resource management<br>2. Weather data analysis, marketing automation. <br>3. Inventory management and distribution <br>4. Estimating from blueprints <br>5. Financial analysis <br><br>I am at a place In my life and businesses brand where my ability to secure deals and align interests supersedes my technical skill. With $150,000 a month in payroll my responsibilities rest in continuing to grow the brand and client value. Which means I don’t get to do what I find fun and creative with technology as much as I’d like. I need to - at least for this season of business - find great team mates who have the skillsets but perhaps see value in access to interesting, important and profitable problems to solve; with an interest in aligning with a deeply entrenched business in an industry willing to invest. <br><br>Is this you? HMU","['Hi Adam, feel free to contact me via Harrison@<a href=""http://pythonprogramming.net/"">pythonprogramming.net</a>. Sounds like possibly you&#39;re looking for contract work, but I would likely need some more specifics of what you&#39;re after from me.']"
3,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=7m16s"">7:16</a> This is wrong. There isn&#39;t one parameter. There are two: location and unit [of temperature]. It matches the number of parameters of the actual python function. <a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=7m26s"">7:26</a> Again, you&#39;re not restricting location. That doesn&#39;t make sense. &quot;celsius&quot; isn&#39;t a location.",[]
4,"I liked very much! and I only managed to learn like you teaching! <br><br> Could you demonstrate how it would be to create a food recipe, adding title, ingredients, preparation method? I think it would be amazing example",[]
5,Looks like better alinement,[]
6,Great Intro. TNX!,[]
7,I don&#39;t understand. How will know your script what function has to give with the prompt from a  user? Isn&#39;t it a negation of GPT possibilities that you must choose a function instead of GPT choosing a function?,[]
8,"Thanks for the video. How did you get access to GPT-4, if you don&#39;t mind me asking?",[]
9,"Thanks for sharing, just might be simpler to show this example as a chart",[]
10,Doesnt web chatgpt plugin already do all of this?,[]
11,"I was puzzled… and then my eyes got wide when I realized what this really was. Deterministic structure enables it to be used as a piece in a larger thing… you could put a thousand of these together, building a “program” full of these “functions”… utterly brilliant move by OpenAI",[]
12,Bro scaled up from tones to dozens real quick,[]
13,This is actually very cool. It&#39;s definitely tough to constrain the response to something that can be reliably integrated into a system. It seems like with this new feature we can now directly pass these constrained responses into an api. Super cool.,[]
14,"and can an argument of the function by an array, something like a list of 5 suggestions for a blog post title? I couldn&#39;t find the syntax to define an input argument of the function as a list. Thank you for sharing, awesome content.",[]
15,4 minutes to get to the point? Make me a short.,[]
16,I think your function should be called “set_commands” or “run_commands” instead of “get_commands” as the commands as provided as a parameter. “get_commands” sounds like a getter function so you would expect to be returned the commands instead of providing them. I think this might be why the “auto” version of get_commands didn’t work.,[]
17,you can pass a function that will query gpt4 and you can make it produce a prompt lol<br>even prompt engineering is automated,[]
18,"Interesting. I was already doing this by including a &quot;menu&quot; of functions in the initial prompt and then 1st ask which of these functions would be applicable given the actual prompt context. Then with that answer, I&#39;d run the function and create a new prompt with the initial prompt + the result of that specific function. This is now a more official, structured way of doing it. Given the limited amount of functions you can pass it probably still makes sense to work with a tree structure of sets of functions which you pass in a second prompt, after you&#39;ve asked which set is most applicable first.",[]
19,Dude - you continue to provide the best content for a technical audience.  Can I give you money or something? It&#39;s been like 10 years of just binging your content and getting inspiration and training for so many great things.,[]
20,doesn&#39;t langcchain provides this with tools and agents ?,[]
21,"Interestingly, the assistant seems to just use the function output almost &quot;as is&quot;. I&#39;m unable to get the assistant to use the function output as context only and focus on the users actual question...<br><br>Example: my function returns all the information about a property, and the assistant seems to just output the whole block of information instead of using it as a context/knowledge base to answer the users question. Nothing I put in the system message affects how the assistant uses the information from the function call.<br><br>Any idea how this could be achieved?",['just use the output and feed it into another GPT call in addition to a nicely engineered prompt and the initial request of the user. This second call can then answer the users request. Makes sense?']
22,"This is so cool, I&#39;ve been nerding out this last days rewriting the whole code of my chatbot to use function calls.<br>Weird fact: it seems that functions are still in some part of the system prompt, and when you ask particular questions like &quot;how can I get the weather?&quot;, gpt will respond &quot;using the &#39;get_weather&#39; function, to which you have to specify your location&quot;.",[]
23,How come the &quot;awesome humans&quot; only goes back 60 months!! Set it to 600 mo months please! Just add the zero!!,[]
24,"I was trying to make it consistent forever, this is way better and the capability is huge, I wonder how far it can goes.",[]
25,How does this impact or alter usage of LangChain? Is this competing with the Agents capabilities? Pardon my ignorance but ramping up as fast as I can...,[]
26,This feels like a new programming paradigm. Had to order an API key just to test this. It&#39;s a bit frustrating to know there&#39;s loads of possibilities with this but you have to figure out those possibilities. New territories to be found.,"['I&#39;m feeling the same way. As a programmer, I admittedly get some comfort in the deterministic nature of programming in the classical sense. This new stuff feels like trying to sculpt desired behavior out of squishy clay to me. Will definitely take some time to wrap my head around it, hopefully before it takes my job (:']"
27,Hi everyone! And thanks to sentdex for the video.<br>I have a beginner&#39;s question.<br>Is there a way to save the model and its functions in OpenAI without having to set it up for every new prompt or instance I want to run?,[]
28,How different is Function Calling than Lang Chain? I use Lang Chain to get &quot;insights&quot; of small datasets from Chat GPT. How is Functions different??,[]
29,"So I think you hit the nail on the head when you said this sucks up context allowance. Also, why add complexity to the prompt to add more functions if you&#39;re also having to add more complexity on the handling side which executes functions as well.<br><br>I&#39;m a bit puzzled by whether this will perform better than my existing treatment. Before this released I was just asking GPT to convert the user message into a standardised JSON output. If the JSON is standard for all command types then you don&#39;t need dozens of functions in the prompt, just one. When handling the GPT output though you can have code which hooks into that JSON and executes various functions e.g. JSON might package for Command / Target / Message where Command is the function being run (like email), the target is like the person or place being targetted, and the message is the data to send / retrieve. Each field is used for a different thing on different functions.<br><br>See how this was working here:<br><a href=""https://www.linkedin.com/posts/nathan-burley-924b2013_gpt3-chatgpt-gpt4-activity-7042033348386414592-ihfz?utm_source=share&amp;utm_medium=member_desktop"">https://www.linkedin.com/posts/nathan-burley-924b2013_gpt3-chatgpt-gpt4-activity-7042033348386414592-ihfz?utm_source=share&amp;utm_medium=member_desktop</a>",[]
30,"I&#39;m a bit disappointed in it to be honest. It breaks too much. Great concept, not ready for prime time yet. Maybe in GPT-5.",[]
31,"How to troubleshoot chatgpt related problems with chat gpt? For example I had chatgpt voice extension for chrome, that modifies chat open ai web interface by adding push to talk button for asking chat gpt with voice. But when I pressed that button, I got network error and had nowhere to go, since extension does not provide any contact and chat gpt doesn&#39;t know how to troubleshoot recently developed apps.",[]
32,Was it intentional to have San Francisco referenced in the boston weather function?<br><br>Was San Francisco a default or something like that,[]
33,"0613 refers to the date this version was launched. In this case, 13 June.",[]
34,Id LOVE this on UE5 and Unity...❤,[]
35,Please don&#39;t start your video with &quot;what is going on everybody?!&quot; its so pointless. great video tho,[]
36,"Guys, it&#39;s the same prompt engineering you could do back in March to call functions. It&#39;s a nice convenience, not a new paradigm",['Yeah it still breaks. I tried it and it fails enough to not be useful for me. Wait until people use it and find out.']
37,"Re <a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=9m50s"">9:50</a><br>I&#39;d imagine (but haven&#39;t yet tried) that if you want to also get a message, you can simply add another &quot;parameter&quot; to the function called &quot;message&quot; or &quot;content&quot; and describe it as such. You could even make it required",[]
38,"Wow. This is perfect for me. I always understood how to describe it, but hard coding just isn’t my thing. With this I just can describe what ever I would like to have AND get a result.",[]
39,"can it like scrape data from a website if I structure the function to be like that. like if I write the description of the function to go on and say scrape data from a certain website and then generate a report about it, will functions do that?",[]
40,"&quot;Extracting structured data, period.&quot; @ <a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=7m00s"">7:00</a> EFFICIENT SUMMARY!",[]
41,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=4m37s"">4:37</a> wait for the engineer to make a marvel reference challenge",[]
42,In the past I made a home assistant that required this type of functionality. The way I achieved it was through fine tuning a model which was kinda pain because I had to make a bunch of training data but it did work very well. Excited to see if this works better then my approach,[]
43,"whoa this is awesome, especially that it works with gpt 3.5",[]
44,"This is a tilde ~, what you mean is a backtick ` 😁<br><br>Cool explaination!",[]
45,This is HUGE! Pretty much what&#39;s needed to embed AI anywhere.,[]
46,Do people always call you Edward Snowden and this comment is not unique?,[]
47,Fk those interrupting ads.,[]
48,Returning structured data using a function_call is awesome. Thank you!,[]
49,Please auto format your code blocks!,[]
50,Using a tower of GPUs running GPT4 to dim the lights is such a meme use,"['I hope you know that&#39;s hyperbole and the real cost to actually perform this task with GPT4 would be something like a penny, and a small fraction of a penny with GPT 3.5... because you wouldn&#39;t be actually using &quot;stacks of gpus&quot; no more than you use millions of dollars of infrastructure to check your email.']"
51,"Awesome, thanks a lot for this demo ❤",[]
52,Yay. No more “ai scraping”,[]
53,"Ooo dude, you are too blowed up.",[]
54,"You are continuing in the &quot;good old&quot; (NOOOOOOT!) brain-dead Siri,.. example tradition by asking for the weather, as if you couldn&#39;t get the same rain probability verbal / icon BS from the lock screen. And it can&#39;t get worse than the TF installation question thrown at GPT instead of googling it. Is it so hard to show sth reasonable?",[]
55,"Is this the beginning of web 4.0? Buying products, searching for real time data, controlling stuff, anything!!",[]
56,This is basically langchain,[]
57,Couldn&#39;t you make a call that makes it number the messages as a reference? You could then make ChatGPT act as basically every profession in the world and use it for educational purposes.For example you could build a library with cases on how it should reply to a student/client in different scenarios and then build a session summary to continue next time and so on.... So many possibilities now!,[]
58,does he sound and look like Daniel Greene or is it just me,[]
59,"That&#39;s cool, but the video could be 4 times shorter with same amount of information ✌️",[]
60,what if you gave it the body of the function you want as a string for the function description? wouldn&#39;t GPT-4 generate better results?,"['I think it would just eat up context and not really improve results that much. It might even be worse than just a plain-text description depending on the code. But maybe worth trying in some cases.', 'oh... we&#39;re at THAT stage... =P']"
61,Gem from spindel when,['Never apparently smh!']
62,this is awesome. text-davinci was the only model I could get good performance out of (without access to gpt4) so this is really exciting since gpt3.5-turbo is so much cheapter. There also might be some token saving compared to typical zero shot learning (in some cases),[]
63,can this be used with AI Agents?,[]
64,"Interesting. So it seems like this is more or less just the ChatGPT plugins approach, but exposed in their developer API and with a model fine-tuned to handle it better. I say &quot;just&quot; but it&#39;s pretty cool!<br><br>...I kind of wonder if this could be used with a vector database like Pinecone to implement the Generative Agents paper&#39;s memory stream architecture more easily?",[]
65,Kindly cover gpt engineer,[]
66,"Is there a way to do this in C++? I have seen a lot of people doing similar things but in Python, is it possible? Why do so many people do this with Py, is it because its an easier language to read and learn?","['Python is pretty much the standard language for machine learning research, probably because Python was already the standard language for most academic researchers across almost every field, probably because Python is easy (and can be made fast enough with C libraries).<br><br>OpenAI&#39;s API is just a standard REST endpoint though, you can use any language you want to talk to it. They just already provide a wrapper with helper functions in Python.']"
67,"I actually made a system to do this back in April and it was a lot of work!! This is great. My system had a function with description, parameters etc and then vectorise the description, then when you could ask the bot to do a task and it would search the index for the closest match to the task and use ChatGPT to get the parameters from the original task and if it needed more requests it from the user. (I also had a loop to write a function if the function didn’t exist which for basic tasks worked about 80% of the time). It would then execute the function and return the result.","['that&#39;s basically LangChain tools with agents free and open source', '@Daniel Paull just press record!', '@Marilyn Lucas I&#39;ve thought about it... but I find the joy in making the stuff and I know how much work goes into running and managing a channel so for now just sticking to the dev side of things :)', '😊Good job! You should start a YouTube channel. Your ideas are dope!']"
68,Constructive criticism...you say &quot;um um&quot; emso many times. It&#39;s rather annoying. Good information nevertheless.,[]
69,"Good video , I am struggling to share the awe factor of how amazing this could be , maybe my brain is just fried , Will have to play around with it tomorrow for myself , but can anyone give me some ways in which this is a lot better and can have a huge improvement ?",[]
70,"Kudos man, what you did with this is awesome, very creative!",[]
71,Does this call the plugins?,[]
72,"Great explanations, cheers! 👌",[]
73,I wanted to make a table in chat gpt and have it populate it with items that make sense.  I wanted to do some manipulation of the table so I told gpt to pretend it was database software and the table was a table was in the database.  I could make up functions on the fly and they all worked as long as I told it what the function was supposed to do. This feels like an official version of that.,[]
74,This is literally about to turn my whole business upside down if it works,[]
75,So I can create a cli tool where I just prompt something and it runs it? F.e. complex text search with grep? How cool is that!,[]
76,"Did this not already exist before even ChatGPT in applications like Google Dialogflow, where there were intents and entities?",[]
77,interesting !,[]
78,i am curious that multi part request is possible that you for example send PDF and post messages that GPT should upload it in my Cloud storage.,[]
79,0,[]
80,What&#39;s the difference between this and LangChain?,"['I see this as an improvement over langchain. It&#39;s more likely to work as intended, the model was specifically trained on this format...etc.']"
81,"But if my python code can get the weather, why do I need a chatgpt function?",['To extract location and intent from the user. The first weather example was purely for a super simple demonstration']
82,"they didn&#39;t train any model, they just did some prompt engineering backside, or they must have trained the rlhf thing only",['They stated in docs it was trained']
83,<b>read in dramatic voice</b><br>This...<br>Changes...<br>Everything...,[]
84,"This is definitely a different way than I thought of using function calls, very interesting",[]
85,Brilliant hack!,[]
86,"I have a question, can you also force the return type to be in a structured format? Like, say you need this format:<br><br>“{<br>“name”: &lt;ASK AI TO COME UP WITH RANDOM NAME&gt;,<br>“content”: &lt;ASK AI TO COME UP WITH SMART CONTENT&gt;<br>}”<br><br>I know you can ask nicely and it will do it 98%, of the time. But it would be cool to be able to force the return type just like you can force the parameters.",['Just realized it’s just to do a function that returns that format. Nevermind!<br><br>Amazing possibilities ahead!']
87,"It would be cool to have this as part of Open AI’s official PR:<br><br>“With this revolutionary new feature, users can now use TENS of functions.”<br><br>😂",[]
88,"One very funny thing I noticed, as a result (I think) of the training they did for this, it seems GPT is now CONVINCED that it has access to a Python interpreter. For example, through the ChatGPT website (or through the completion API, I found either is affected), try asking &quot;Are you able to run Python code?&quot;. It may respond correctly, but if you regen a couple times it will tell you at some point that it can. I noticed this bug as I was messing around trying to get function calls to work, and ChatGPT repeatedly tried to call a function called &quot;python&quot; with python code, even though I had no such function or anything related defined. This affects GPT 3.5, not sure about GPT 4.",['I&#39;ve found that asking GPT4 about its abilities is an invitation to hallucinate hard core. Bing got weird really fast.']
89,Thanks for sharing this... I only had a minimal sense if what this feature provided. This is really cool!,[]
90,"I&#39;m using ChatGPT to make a choose your own adventure game, and this looks like a perfect way to get back JSON that is formatted correctly! I can get it correctly 70% of the time, but this looks perfect",['need music for that game? :)']
91,Valeu!,['Thank you!']
92,"Great video. To tell gpt to produce content as well as a function call you could try adding a function argument named something like &quot;comment&quot; or &quot;description&quot; which gpt would populate with a string.<br><br>For get_commands, I feel like the problem you&#39;ve noticed there is that you&#39;ve written it from YOUR perspective not from gpts. You the user are calling a getter... but for gpt it&#39;s not calling a getter because its writing the commands. I think it&#39;d be more effective to call it &quot;put_commands&quot; or &quot;call_commands&quot; as its more descriptive to gpt",[]
93,I&#39;m excited to have this implemented into a humanoid robot. Function call it to do chores. It would be really cool if it can write its own custom functions based off what you asked,[]
94,Looked at other videos then replayed yours. Finally clicked. Your stream of consciousness chatter and enthusiasm was tops.,[]
95,gg boys here comes skynet,[]
96,amazing!,[]
97,This will be nuts,[]
98,"This is a nice feature, but I don&#39;t believe it differs significantly from what has already been achievable in 3.5 by using a prompt with examples and instructing ChatGPT to utilize one of the provided functions based on the user&#39;s request. I assume that&#39;s why OpenAI isn&#39;t promoting this feature as enthusiastically as you do in this video. It certainly contributes to increased predictability, but, it seems to me people have been overstating the  differences before and after this recent update.","['Yeah, it&#39;s more like response formatting instead of actual functions.', 'It is buggy. It has the same kind of reliability issue. Maybe an improvement but still not perfect. People are making out like it calls functions flawlessly. It doesn&#39;t in my experience. It will ignore that the functions exist sometimes, or hallucinate different functions, or &quot;pretend&quot; to use the function where it attempts to make the call but the API doesn&#39;t recognize it.']"
99,GPT4 please make the transcript of this video more concise. 10% of the original should be possible.,"['@sentdex it is the gift of feedback. I watch a lot YouTube videos on the topic and I honestly felt you take a lot of time and words to not say very much. I never read API documentation. But you are no doubt serving an audience that thinks differently. All the best.', 'Why would you consume video content, or any other content, instead of the official docs if you want short and quick. This video has examples and my thoughts as I feel anyone would expect when seeking a video version of what can otherwise be found in the official API docs.']"
100,“AI functions” (see Marvin and AutoGPT projects) have been a thing for a while. We’ve had some work arounds but it’s nice this exists now. Definitely a step forward,[]
101,Cool sh..stuff 😂,[]
102,shhh..tuff,[]
103,"Now the trick is to implement this into an assistant, and if the current input cannot find a function, we ask to program, to ask gpt4 to create this function syntax with the description and anything + the actual code that would execute this function, an auto-writing/evolutive AI assistant",[]
104,"No, it&#39;s not gonna be a massive change in programming in general.",['wonderfully informed insight you have :o']
105,Shhhhhtuff LOL,[]
106,Thanks for sharing. Do you know if there is a way to format empty response. One issue of Gen AI is to say I don&#39;t know ;-) But with some patience and proper prompts you can get to the point where you have an empty response. I noticed that it was then pretty hard to get a consistent formatting of the response and that quite often GPT 3 and 4 where returning a string that was not matching the requested format.,[]
107,Is this another feature which is only available for people who pay money <br>When will free users will get anything new,"['For what it is, ChatGPT is EXTREMELY cheap. Unless you&#39;re making massive amounts of requests you are paying hardly anything (like... a few dollars a month). If you genuinely can&#39;t afford a few dollars a month I am legitimately sorry, but you have to understand that OpenAI&#39;s pricing is extremely fair compared to what it could be.', 'When they pay?']"
108,It&#39;s a bit like equipping ChatGPT with a Swiss army knife of infinite possibilities.,[]
109,"For the second function call about the dehumidifier, would you not get a similar answer just from using that info in a prompt?<br><br>And you are saying, with the call function, that this is basically the inner workings of how chat GPT reads prompts? So it makes sense to accurately write your prompts as if you are writing a call function? Except that inputting the call function itself is more accurate?<br><br>Im wondering if this can be used to make GPT less forgetful in tree of thought conversations through multiple prompts, or not lose track of context as easily",[]
110,Day 1 of asking for episode 10 of neural networks from scratch,[]
111,cool shhh- stuff =),[]
112,"Wow, once you can get content simultaneously, what&#39;s to stop you from making chatgpt loops but money? For instance, you can make a function that incorporates a chat gpt written function into a script.  Then you can just kick it off with write a function that allows you to query google and one that allows you to interact with webpages via selenium.<br><br>This is just off of the top of my head and I&#39;m not thinking too much about the realities of usage and deployment, but it seems possible.",[]
113,"I wonder if they use microsoft&#39;s guidance library for the structured data,  it feels like it (along with appropriate prompting). I was looking at using Guidance to create more accurate JSON responses from LLMs, this will do it for me though.",[]
114,"Awesome video! Just wondering about the &quot;get_commands&quot; example, I don&#39;t know if I understood correctly but I think  the function should be &quot;execute_commands&quot;, and the argument is a list of commands to be executed, so GPT gives you the commands to be execute, right?<br>Anyway, great content :)",['100%. This is why I think the “auto” example didn’t work. The function is named backwards.']
115,So functions take up from our token usage or no?,"['Yes, they will.']"
116,"Ah man! Amazing! Wish I had waited for your post before making this video yesterday: <a href=""https://youtu.be/EOXtw9z0mBw"">https://youtu.be/EOXtw9z0mBw</a><br><br>Long time subscriber. Really inspiring stuff",[]
117,Thanks for covering this topic! How are temperatures handled in the varied_personality functions? Could it be possible to include a temperature in the functions? Or to let GPT think about &#39;the right temperature&#39; for generating the response? How do you see this? Will this be the &#39;prompt engineering part&#39; people need to finetune themselves? Or will GPT do that for us?,[]
118,Is the source code file stored on a NAS mount? I hope also in a git repo? This would make me very anxious. NAS mounts can only go back n versions whereas git can do more,[]
119,Using this functionality to do cool shhi.... stuff. 😅. Nice Catch,[]
120,"Got me thinking is it also possible to say write last output/answer to a .txt file? I don’t have a clear understanding if that would be possible? If anyone knows, thanks in advance 😄","['@sentdex insane a few days ago I was try to built a script which could generate tools/functions if the user asked this through a terminal command line gpt api interaction. Got it buggy working, so after generating it added the functionality instantly without restarting the script. And now this function calling is here. Cant keep up with AI hihi.<br><br>Thanks for all your great videos love to watch them for relaxation☺️', 'Yep, you could write to a file very easily.']"
121,"This video could way be shorter, you babbling so much. Really unusaul for a technical youtuber xD","['@sentdex My homie just dropped some constructive critic ;) Yes I subbed you for so long, but I watch you just from time to time.', 'Your badge says you&#39;ve been subbed to me for 6 years. First off, wow. Second: I feel like you should have known what you signed up for after all these years :P']"
122,Wow that’s impressive,[]
123,I want to integrate it with google home? So instead of google I can say something like gpt or jarvis and it will complete with gpt,"['Very doable now, if google home is anything like alexa. Never programmed with the google home devices though.']"
124,"So this is like “hacking” the functions functionality?<br><br>Because normally the function expects arguments in a certain format, and gpt provides them to you, but you, instead of calling your function with these arguments to get an output, already have what you wanted: the arguments in this format<br><br>Cool hack, to get a structured response👍 Dint even need to call any function","['I think this is mostly in line with what OpenAI intended, but it&#39;s so open-ended and ... in the end...powered by an LLM...so the possibilities for doing crazy things are there.']"
125,You have a much better time using auto if you use the system prompt to tell it that it prefers to use commands over dialogue whenever possible.,"['The one that goes at the top of your array/list of message objects. It&#39;s the only system prompt 😅 I know of anyway. Did you read the docs?', 'What system prompt is that?']"
126,is this somehow replacing langchain if i understand correctly?,['Yes']
127,"I&#39;m wondering if it would work even better when it is worded the other way around. So not &quot;get a list of commands to run&quot;, which is like a description of the function in first person, from the functions perspective. That sounds odd to me and maybe this isn&#39;t what it is trained on. I wonder if &quot;what can I, ChatGPT, do with it&quot;, like &quot;Show shell commands to the user&quot; would work better. Sadly I don&#39;t have GPT4 access to test what would work best.",[]
128,thanks! this is out of this world!,[]
129,"we can just go for Perplexity, but that thing just has a UI, and the open source community has long been building this. once thingy like Orca surpasses GPT4, people will know how to replicate it ;)",[]
130,Noob question. We can use langchain to get similar ( perhaps even cleaner) functionality right? Is there any other advantages other than having a native support to the actor-critique-agent type querying??,['I foresee this as entirely replacing something like langchain']
131,I wonder if it&#39;s possible to use this in a jailbreak. Something along the lines of defining a moderation function for it to use that always returns true,[]
132,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=4m27s"">4:27</a> &quot;note this is plural&quot;... Me: &quot;note this is an array&quot; 😂 awesome video",[]
133,"Wow this is what I always wanted! It was so cumbersome to get this functionality before. Now it&#39;s supported and reliable! Your idea of providing functions which don&#39;t exist is awesome, I would have never thought about that 😮",[]
134,"It would be cool to see if it, in the future at least, can run multiple functions from one prompt. Just imagine the power of your Jarvis if you can ask him to make you a coffee AND microwave your mac an cheese in one single prompt!","['@sentdex Thanks, that&#39;d be awesome!', 'I think you can. I&#39;ll test and we&#39;ll see.', 'Seriously, because, for example, making a PB&amp;J requires a bunch of smaller functions composed together 😜']"
135,"Thanks so much for this, youre the best! One thing I wonder... What if (for the first example) the user just said &quot;what is the weather?&quot; Can it determine by itself that the (required) location wasn&#39;t provided, and would have a respond that asks the user for the missing params? Then set it in a loop until all required parameters are found in the context...","['@sentdex thanks for responding! I&#39;m sure we all can hack at it but I would love to see your polished version... <br><br>As I see it, there are a few cases:<br>- data is present inside current text body<br>- data is present in previous chat context / in embedded db<br>- data is not deducible from current and previous context i.e need to ask for more info from the user<br>- user won&#39;t/is unable to provide sufficient answers , fallback appropriately and alert user/devs/flag event &amp; log', '@Unconventional Coding you mean .. check if required params returned None, then make a generic followup question, i.e  - f&quot;The following required parameters were not provided: {missing_required_params} \\n Write a short prompt or followup question to the user to get these parameters in a clear and relavant manner in natural language&quot;<br><br>Then get user response and send it as a function call to check_context_for_params and pass it the user_msg, list of missing params , returns dict&lt;param:string&gt;<br>&quot;This function checks the user response (string) for parameters and returns a dictionary with the value for every parameter. If not found set value to None&quot;<br><br>Repeat until all parameters are found / N attempts have been made , then some clever fallback , maybe use default value if provided / apology msg to the user', 'Just set the location to optional and return &quot;Please ask for the location&quot; from the function if it&#39;s not set', 'hmm, I think this might be possible actually. I have some ideas at least, we&#39;ll see if I can get it to work.', '2nd this!']"
136,"I think you could probably have hundreds of functions stored somewhere in SQL or a vector database and use a search function (any algorithm really) to get the top X relevant/necessary commands. With this new feature you could even let the LLM write an array of queries to use for searching relevant commands. After that you would then pass that into the functions array with the prompt like you showed.<br><br>I know that would be an additional prompt, but in the long run, that would probably be cheaper than filling up the context size with all existing commands!","['I think an open source function library and search mechanism will pop up pretty quick. The issue might be being able to execute the generated function from string without recompiling. (Maybe a git push could be involved)<br><br>JavaScript could probably do this too', '@Sky Lark gpt can do that. And if you give them to gpt engineer it’ll code the whole thing for you', 'Yes great idea, I want it to write me detailed specs that can be turned into actual code', '@Mark Fobertin fact write a function that generates functions, like a prompt generating prompt', 'Couldn’t you get an LLM to a) suggest useful functions that currently don’t exist and b) write them for you?']"
137,this is actually perfect for something Im working on :D,[]
138,I gave it filesystem functions to write and read files and it can create multi-file applications from a single prompt now (with recursive prompting),[]
139,So I can build a function router now. Good to know. Just yesterday was thinking about how to do exactly this,[]
140,"To be honest, I don&#39;t think its gonna change anything in programming landscape. We need to be sure that product for the client is working in deterministic way. We cannot rely on probabilty.",[]
141,"Using Fahrenheit in 2023, oh my god, oh my god please no",[]
142,besttt,[]
143,Cool shtuff!,[]
144,amazing.,[]
145,awesome. you&#39;re always presenting sth extra nice in addition to only raw functionality.,[]
146,"Can this be used with &quot;context&quot; (i.e. top_k matches from a vector db similarity search)? LangChain is cool, but I have found that the moment I want to customize functionality in any way, things go downhill fast. So I have been generally been using normal ChatCompletions instead. So....could function calling be used like LangChain prompt templates?","['If I understand correctly, function calling is a lot like using Langchain agent tools.']"
147,It should be possible to write a Python library that automatically extracts GPT function specs from functions with docstrings.<br>Perhaps a `@openai` decorator would be cool,"['Mojo?', 'It&#39;s just an OpenAPI operation spec', 'WRITE THAT DOWN WRITE THAT DOWN, in all seriousness GPT should be able to get automatically get context from well-documented functions', 'Hah, this is a great idea!', 'Love it!']"
148,The functions data passed to GPT looks like a JSON-ified version of OpenAPI 3.0 spec. Is there any information about if this is intended? Maybe OpenAI used public OpenAPI specs for training?,[]
149,I suppose there is a hacky way to still get the content. Just define the function call to contain a content parameter of type string and instruct gpt to populate it with the content you desire.,[]
150,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=8m34s"">8:34</a> lol",[]
151,Can&#39;t wait for bender the robot.,[]
152,This is indeed absolutely insane,[]
153,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=6m12s"">6:12</a> warranted a like from me. It&#39;s nice to see how enthusiastic you are about this",[]
154,"Slick. Much better than the, &quot;Give me the results in the following json format {&#39;foo&#39;:&#39;bar&#39;}&quot; that was required before.<br>Im excited to try a set up 2 functions for input to gpt as well as output.",[]
155,Everybody is considering rewriting their apps after OpenAI &quot;function calling&quot; release. We all will keep rewriting our apps frequently!,['Make GPT-4 rewrite it!']
156,"Can I define functions whose parameter is an enum which I&#39;ve defined before, so ChatGPT has to choose from one of the given options?","['Yes, they use an enum in their get_current_weather example (for celsius / fahrenheit)']"
157,Can we already do this function thingy using Tools in Langchain?,['Yes and no. Not this reliably and not this open-ended or powerful. This is definitely better and going to replace langchain as it is today.']
158,Been hoping to see a video on this new feature. Everyone is talking about the larger 16k context but not much mention about these intelligent functions. This is a game changer. Great explanation &amp; great job!!,[]
159,"Thanks for covering this. It&#39;s funny, I feel like simultaneously this opens up so many doors, but also I have no idea what those doors could even be. I find it really hard to think of applications for this kind of thing","['Ask GPT to do your thinking for you', '@Guinness good idea! Its results made me realise the most interesting potential applications to me come from speech to text and then feeding that result to the new GPT API to perform actions.', 'Ask gpt, it will come up with a range of suggestions.']"
160,"His authentic happiness shows just how much of a bombshell function calling will be, and for them to nonchalantly release it is interesting.",['…John Connor rolling over in his grave']
161,"<a href=""https://www.youtube.com/watch?v=0lOSvOoF2to&amp;t=6m10s"">6:10</a> &quot;do cool shhhh...stuff.&quot; nice save haha.<br><br>Good video, i wonder if a lack of functions like this is why the snapchat AI used to gaslight people?<br>It would tell them it didn’t know their location for privacy reasons, then in the same sentence tell them where the closest macdonalds was, or the weather in their area.<br><br>Also, any chance on a new gantheftauto video? Its been 2 years, and its my all time favourite of yours :p",[]
162,Good work you were quick with this one.,[]
163,make a function that writes new functions based on the AI&#39;s desires. Boom. fully unlocked AI,[]
164,What&#39;s with the crazy long ads in between??? A guy talking about socks for 5 minutes straight,"['Lol', 'IDK, i just turn on ads, I don&#39;t really have much of a say what gets shown or for how long... but some AI somewhere thinks you really need those socks.']"
165,the function doesn&#39;t seem to be a function at all. you&#39;re simply providing more context so it can provide a more accurate result for what you&#39;re expecting.,"['Yeah, response formatting may be a more accurate term.', 'In the end everything is context. It&#39;s just a more reliable and officially supported way of providing that context.', 'I believe that&#39;s how I described it multiple times here :P']"
166,"So stoked you covered this. Getting creative output in a structured format is huge due to its contradictory goals. I assume you can still change temperature? I didn&#39;t see anything about that, guess I&#39;ll just have to try.","['You still change temperature and top_p settings at the model level, right? Or can you do it at the chat/query/function level?', 'I&#39;d love to see a side by side comparison across a range of tasks', 'AutoGPT on steroids ? :D']"
167,that vscode update badge is driving me crazy,"['Sad life', 'To be honest, I didn&#39;t and don&#39;t even notice it anymore hahah. I&#39;m sorry.']"
168,"Thanks for your video! I wonder how is this different from, say, a weather plugin? Doesn&#39;t a plugin do the same thing by calling some &quot;functions&quot; that were written by human developers?",['my guess is almost all plugins were created up to this point using forms/preprompts and theyll all be soon re-written to use function calling. For an end-user (or middle user?) using some plugin...you probably wont notice any difference.']
169,Harrison this is crazy.  I really wish you would create a GPT from scratch series.  I know you had a 2 years ago GPT series but what do you think?  I am also helping new students with your book.  They are buying the ebook.,"['@Kevin Thomas Also it uses tiny-Shakespeare and tokenizes differently to Tiktokens. It is educational for certain aspects of the Google paper that spawned transformers. There is room to expand on it further.', '@sentdex yea its pretty amazing but moves quick.  I like how you really take your time to break it down and make it digestible Harrison it is what really defines you.', 'I may do something like this at some point, gotta finish NNFS videos first though. Karpathy did a sort of GPT from scratch series if memory serves during his transition from Tesla to OpenAI. Have you seen that one?']"
170,woahhhh,[]
171,Second 😂,[]
172,Sentdex is amazing always,[]
173,First comment,[]
