,comment,replies
0,"Do you want to learn technology from me? Check <a href=""https://codebasics.io/"">https://codebasics.io/</a> for my affordable video courses.",['Hi.. Could you please upload a video for RoBERTa?']
1,thanks sir for this great series,[]
2,"print(&quot;Very explicit, thanks for all you do for the AI/ML learning nation&quot;)",[]
3,"Lo pondr√© en mi dedicatoria de tesis cuando lo termine, gracias por el video",[]
4,Thanks,[]
5,Great video. Thanks,[]
6,Really learning what is BERT. Great going,[]
7,"Baby don&#39;t love me, don&#39;t love me, no more....",[]
8,"I thought watching ads are the &quot;fee&quot; of watching this video, instead thumbs up :)",[]
9,"Very nice video! Shortly introduce the concepts, then jump into coding practice with detail explanation. I learned a lot during my following and experimenting the coding. Thanks. Can‚Äôt wait to explore more about the coming classes.",[]
10,"What is padding in word embeddings? Does it mean that the first sentence has just 3 words in it so remaining 125 arrays for it will be padded with 0? for 2nd sentence example in the video, there are 4 sentences. So for this 128-4=124 arrays would be padded with 0? Is this interpretation of padding in word embedings correct?",[]
11,"Thankyou for your Explaination üòÄüòÄüòÄüòÄ, it&#39;s easier to understand from your video",[]
12,The BERT gives different results on every run in text classification. How can the problem be solved?,[]
13,Great Work. Thank you. Kudos to you man.,[]
14,‚ù§,[]
15,The examples in tensorflow help a lot to understand how everything works,[]
16,Now you are getting funny<br>Thank you so much!!,[]
17,i have a problem &#39;ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado:&#39;... Does anyone know what can I do?,[]
18,I paid my fees. ü§£ü§£ü§£,[]
19,"<a href=""https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=5m25s"">5:25</a> word2vec problem: &quot;ashe pashe&quot; ke ase ta dekhe NA",[]
20,"Ow Thank you. This is interesting tutorial. But can we use BERT directly for our local non-English language. If it is so, how can we use it? If it is not possible, how can we develop an algorithm like BERT for our local language too? I asked this question because most of the tutorials here in YouTube is given by English examples and models and those models cannot be applied to other local languages. For example, we cannot use Spacy POS Tagger for our local language. That is the big problem for us to develop NLP applications or model using those pretrained models. So, if it possible I like you to give us a methods for using models like BERT for our local languages too. I am very interested if it is so.",[]
21,"Need a kind of teacher like you in Engineering university, Most of them can&#39;t trach properly. They judge by only exam.",[]
22,"<a href=""https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=14m45s"">14:45</a> to my experiments, the number of 1 - CLS is not equal to the number of words.... it seems related to the length of the words and the sentence, am I wrong? Thanks",[]
23,thanks,[]
24,love your video,[]
25,Really so helpful. Thanks a lot Sir. üëç,[]
26,Great video! thank you!,[]
27,Thank you so much Sir ! Your videos are very informative in a understandable way :D,[]
28,How to analyze semantic opacity of multi word expression? Is that true using BERT model? Or we should be use CBOW and Skip-gram?,[]
29,Thank you so much.,[]
30,"So helpful for quick understanding, thanks a lot!",[]
31,"Brilliant, made me understand the concepts at a go.",[]
32,Natural teaching skills. Brilliant!,[]
33,"Hey, very imformative video! Could you please make a video on how to use the BERT model for text question and answering locally? <br>Thanks",[]
34,Thank you so much. It is really great to help to newbies in NLP.,[]
35,Everybody asking &quot;What is Bert&quot; but noone asking &quot;How is Bert&quot;,[]
36,well done,[]
37,Hi.. Could you please upload a video with RoBERTa ?,[]
38,"Great video, filled many gaps I had in how BERT is used.  Thank you!",['Glad it helped!']
39,transformer and t5 model video need sir....,[]
40,"Hello Sir,<br>Can you please clarify the dimension vs padding at <a href=""https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=1194s"">https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=1194s</a>?",[]
41,"Need a little more info on how we got 2, 128, 768....why will we need padding here?",[]
42,Such a nice concise work. Thanks,[]
43,more amazing content,[]
44,"Thanks for the video , please i have been having issues running tensorflow_hub and tensorflow_text, please can you help me out here",[]
45,Amazing explanation. Can you plz build a model using BERT fine tuning,[]
46,a great video!  can we get an embedding for a corpus (as well as their word and sentence embeddings) out of Bert?,[]
47,"Hi , can you explain ALBEF?",[]
48,thanks for using Mahmudullah as an Example,[]
49,"If bert have fixed size padding for each sentence, does it lead to wastage of memory every time it runs??",[]
50,"great explanation, easy and fantastic.",[]
51,Can&#39;t be much easier or better than this. Thank you for such a greare video and awesome explanation.,[]
52,error no named module called tensorflow hub error in jypter notebook,[]
53,Dank je wel!,[]
54,"Thank you so much, loved it. Very well explained.",[]
55,"Good stuff, but I need to read more.",[]
56,how can we use this for translation?,[]
57,Congrats from Brazil! :),[]
58,great effort,[]
59,Has anyone got error due to tensorflow_text lib?,[]
60,"Superb Dhawal........By explaining with code, all doubt has been cleared now. Thank you so much",[]
61,"I really, really learn many new techniques from your video continue appreciate",['Glad to hear that!']
62,"Sir, can you upload a video content about XLNet concept and it‚Äôs implementation.? Thanks in advance sir. Love from Bangladesh",[]
63,i owe you for this. so well explained.,[]
64,thanks,[]
65,Hi I have 2.2 lakh record of short description and assignment group which is in categorical approx unique count is 450  and I need to classify assignment group basis of words,['I tried the way your are doing but not worked for me. Is any suggestions']
66,"super consice explanation, ultra satafying while watching it, keep going!",[]
67,dear i need a BERT developer can you help me?<br>kindly provide contact no.,[]
68,Thank you!,[]
69,You are my guru.  Please keep guiding us.,[]
70,perfect tutorial,[]
71,"You made it look so easy! awesome. So basically i can just use the pre process URL and encoder url, generate the word embeddings and feed it as input to neural network??????","['@codebasics well you just earned another subscriberüòÉüëç', 'Yup']"
72,thank you sir,[]
73,Really inspiring.,[]
74,You still my favorite instructor,[]
75,Please dont add background music while explaining..,[]
76,One of the best tutorials about BERT I&#39;ve seen so far thanks :),[]
77,great work,[]
78,Excellent Explanation Sir! Learned a lot. üëèExpecting more sir.,[]
79,Do this work for languages other than english?,[]
80,"Great video super explanation this is useful for classifying sentences, what if I have conversations to classify, Where is conversation has multiple sentences, so how to classify a conversation into a particular class where a conversation has multiple sentences inside. The documentation of tenser flow explains how to classify sentences But not how to classify conversations in to a particular class",[]
81,Thank you for explaining BERT. The pace and progression was extremely well executed.,[]
82,Excellent video.,[]
83,The G.O.A.T of teaching üòç,[]
84,Can I train a chat bot using Bert model?,[]
85,code basics: I&#39;m going to explain in simple language as if you were a high school student <br>me( a high school student) : I see this as a absolute win,[]
86,Pls do a video on toxic comment classification using Bert (jigsaw competition)pls pls,['Point noted']
87,Really helpful brother!!!!,[]
88,"thanks a lot for this great explanation, excuse me i&#39;m confused between word embedding and subword embedding. does the embeddings here for word or subword , please ?",[]
89,Great Video sir Thank u so much‚ù§Ô∏è,[]
90,Can you explain us Rem-Bert ? Thanks in advance,[]
91,Thanks,[]
92,some more examples with real-time problem must be added in programming. rest all pre-knowledge good. keep it up,[]
93,Respected Sir your videos are very good. I request your sir please cover the concepts of Attention Model and Transformer Model.,[]
94,Thank you so much. I love the way you explain the codes.,[]
95,Thanks sir üôè,[]
96,Sir you made this look so easy,[]
97,bert_model = hub.keras_layer(encoder_url)<br>showing error for this as &#39;module&#39; object is not callable,[]
98,&quot;bert_en&quot; what is the meaning of &quot;en&quot;? is it english? so it will be better if this for english? what if i wanna train with different language? better i use this or another bert model??,[]
99,"<a href=""https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=1m27s"">1:27</a> You earn a subscriber.",[]
100,Great job. Nice and clear explanation.,[]
101,Hello every one &#39;<br>I got a issue while importing tensorflow text ..<br><br>No module named &#39;tensorflow_text&#39;<br><br> i have already installed all the required libraries .. tensorflow version - &#39;2.6.0&#39;<br>i have already installed --&gt; pip install tensorflow_text,[]
102,super happy to give you a massive üëçüèª,[]
103,I really appreciate your efforts.<br> Kindly tell me BERT is supervised or Unsupervised machine learning method.,[]
104,"Thank you a lot, it simplified everything to me so well.",['Glad it helped!']
105,Excellent explanation about BERT. The article which you suggested is awesome. Thank you soo much sir :),['yup that article is awesome.']
106,Thumbs up and subscribed. Thank you very much!,[]
107,great,[]
108,"This video was key for me to understand the functionality of bert, its inputs and outputs. Keep that stuff on! You&#39;re amazing!","['@codebasics Love your stuff. Just an FYI @<a href=""https://www.youtube.com/watch?v=7kLi8u2dJz0&amp;t=9m21s"">9:21</a> under the How was it trained slide, you have a typo (mased language model instead of masked language model) .', 'Glad it was helpful!']"
109,Very well explained. You really posses the ability to simplify the topics. Thank you s9 much.,[]
110,Very simple and concise explanation!! Thanks so much :),[]
111,really great content. It was really helpful.,['Glad you think so!']
112,You are the best... Thanks a ton for such a nice tutorial :),[]
113,Exactly what I need!,[]
114,"THaaanks alot, it was a very helpful tutorial.",['Glad it helped!']
115,your effort and time for creating good videos are highly appreciated!,[]
116,"hello, thank you for this tutorial. I have problems installing tensorflow_text in my conda environment. How did you do that?",[]
117,You are amazing.,[]
118,Thank you so much. I love the way you explain the codes.,['Glad you like them!']
119,Hi Dhaval<br><br>You are master !! <br><br>Thank you very much for your teaching !!,[]
120,This is awesome sir. I can&#39;t thank you enough,[]
121,"Hi Dhaval,<br><br>This is the best Bert based text classification tutorials . Thanks from Krish",[]
122,You are teaching in Nice manner. Can we have NER task Architecture explanation for Bert &amp; How it is Working and some code for implementation of NER,[]
123,thanks sir for these videos,['Glad you like them!']
124,love  from bangladesh,[]
125,Informative video. Thanks,[]
126,Sir but why it create an embedding of length 768?,[]
127,Informative and easy to learn ..... Keep adding videos,[]
128,Please make video on NER using BERT with re-training again with own data.,[]
129,"What could be done if, for some reason, your text has <i>more</i> than 128 words?","['@Developer Harsh  IKR. My question was exactly on purpose: what IF that limit is exceeded?', 'BERT can handle a maximum length of 512']"
130,"Great stuff!  You have a real knack for breaking down complex topics into simple, intuitive concepts.  Thank you!",[]
131,"Good explanation sir , tq",['You&#39;re most welcome']
132,"Great stuff, Sir.",[]
133,Sir in 12th standard less than 60%are students eligible to get  data science job,['Indeed']
134,"Part 2: Text classification using BERT: <a href=""https://youtu.be/D9yyt6BfgAM"">https://youtu.be/D9yyt6BfgAM</a>",['why private? if any error in the video then you can mark them in comments or edit even after published.']
135,"To the world, you may be just a teacher but to me, you are a hero! Wishing you a Happy Guru Purnima!¬†I bow to the one who has inspired me and taught the¬†right way of life! You are the inspiration who made me overcome every hurdle in python ‚ù§Ô∏è",['üòäüòä happy guru purnima üòäüòä']
136,they way you teach it is just awesome. I tried to learn topics from multiple source but your way is out of the box. Thank you so much.,[]
137,Thank u for this vid:),['Glad it was helpful!']
138,Happy Gurupornima,['üòäüôèüôè']
139,How many more videos u think are remaining in this deep learning course?,"['To be honest I am not sure but I would say 90% complete. I have covered basics of deep learning, CNN, RNN and now just finishing last few videos of RNN/NLP']"
140,"nicely explained, thank you!",['Glad it was helpful!']
141,"Please I tried connecting with you on Facebook,  I will appreciate a feedback. Thank you",[]
142,Yesss Deep Learning is back,['üî•üî•üî•üòäü•≥']
143,Thank u sir for explaining in sch a simple language,['Glad you liked it']
144,Your teaching style and methodology is awesome. God bless you.,['üòäüôèüôè']
145,nice!,[]
146,Great session for beginners. When will be the part 2 of this session held. Please inform,"['you are every where in the YouTube world. I have seen you in Andrew ml, and I have seen you in many places. Super  I think I am learning properly.  I am seeing you for last 7 months continuously.', 'Part 2 will be live tomorrow: <a href=""https://youtu.be/D9yyt6BfgAM"">https://youtu.be/D9yyt6BfgAM</a>']"
147,Thanks for this series on deep learning. Please consider having NLP deeplearnig series with PyTorch too.,[]
148,YES!! DL series is being continued!!!!<br>I can tell this is gonna be good.,[]
149,Please continue your dsa in python playlist üôè it&#39;s a request üôè,[]
150,Great this would be helpful...<br>Dhaval do you have any tutorial on  predictive maintenance like for example predicting remaining useful life of Valves.... Please redirect me to resources which has solution approach Data sets etc.<br>Thanks,[]
151,Sir do more video on powerbi,[]
152,How Many Videos are in this Playlist?,[]
153,Sir aap kuch help kr skte ho,[]
154,Sir aapke personal baar krne tha,[]
